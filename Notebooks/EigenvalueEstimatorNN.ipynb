{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "from numba import jit, autojit\n",
    "from scipy.sparse import csc_matrix, dia_matrix, diags\n",
    "from scipy.sparse.linalg import eigs, eigsh\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor as NN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "import pandas as pd\n",
    "\n",
    "x = np.linspace(-10,10,1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise constants for the softcore potential:\n",
    "v = 200# set =0 for particle in a box case\n",
    "n = 2\n",
    "b = 2\n",
    "\n",
    "\n",
    "@np.vectorize\n",
    "def potential_softcore(xk, t):\n",
    "    numerator = -v\n",
    "    denominator = (np.abs(xk)**n + b**n)**(1/n)\n",
    "    return numerator/denominator\n",
    "\n",
    "@np.vectorize\n",
    "def potential_linear_with_time(xk, t):\n",
    "    alpha = 5\n",
    "    numerator = -v\n",
    "    denominator = (np.abs(xk)**n + b**n)**(1/n)\n",
    "    return numerator/denominator + alpha*t*xk\n",
    "\n",
    "@np.vectorize\n",
    "def potential_oscillating_with_time(xk,t):\n",
    "    omega = 5\n",
    "    numerator = -v\n",
    "    denominator = (np.abs(xk)**n + b**n)**(1/n)\n",
    "    return numerator/denominator + np.sin(t*omega)*xk\n",
    "\n",
    "\"\"\"\n",
    "Choose which potential function to use:\n",
    "\"\"\"\n",
    "potential = potential_softcore\n",
    "\n",
    "def gen_diag_Hamiltonian(x_arr):\n",
    "    \n",
    "    dx2 = -1/(2*(np.abs(x_arr[0]-x_arr[1])**2))\n",
    "    \n",
    "    centre_diag = -(5/2)*np.ones_like(x_arr)*dx2\n",
    "    one_off_diag = (4/3)*np.ones_like(x_arr[:-1])*dx2    \n",
    "    two_off_diag = -(1/12)*np.ones_like(x_arr[:-2])*dx2\n",
    "    \n",
    "    H = diags([centre_diag,one_off_diag,one_off_diag,two_off_diag,two_off_diag],[0,1,-1,2,-2])\n",
    "    return H\n",
    "\n",
    "def gen_diag_V(x_arr, potential_func, t):\n",
    "    V = potential_func(x_arr, t)\n",
    "    return diags([V],[0])\n",
    "\n",
    "H_without_V = gen_diag_Hamiltonian(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_potential(V):\n",
    "    \"\"\"\n",
    "    This returns information on the shape of the potential distribution,\n",
    "    to be used by the eigenvalue-predictor\n",
    "    \"\"\"\n",
    "    maxV = np.max(V)\n",
    "    minV = np.min(V)\n",
    "    varianceV = np.var(V)\n",
    "    meanV = np.mean(V)\n",
    "    medianV = np.median(V)\n",
    "    return [maxV,minV,varianceV,meanV,medianV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>variance</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>min_eigval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-97.665835</td>\n",
       "      <td>-498.0</td>\n",
       "      <td>15077.510078</td>\n",
       "      <td>-230.186307</td>\n",
       "      <td>-184.952557</td>\n",
       "      <td>-492.490153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-97.763893</td>\n",
       "      <td>-498.5</td>\n",
       "      <td>15107.801402</td>\n",
       "      <td>-230.417418</td>\n",
       "      <td>-185.138252</td>\n",
       "      <td>-492.987353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-97.861951</td>\n",
       "      <td>-499.0</td>\n",
       "      <td>15138.123123</td>\n",
       "      <td>-230.648529</td>\n",
       "      <td>-185.323948</td>\n",
       "      <td>-493.484555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-97.960010</td>\n",
       "      <td>-499.5</td>\n",
       "      <td>15168.475242</td>\n",
       "      <td>-230.879639</td>\n",
       "      <td>-185.509643</td>\n",
       "      <td>-493.981759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>-98.058068</td>\n",
       "      <td>-500.0</td>\n",
       "      <td>15198.857759</td>\n",
       "      <td>-231.110750</td>\n",
       "      <td>-185.695338</td>\n",
       "      <td>-494.478964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            max    min      variance        mean      median  min_eigval\n",
       "996  -97.665835 -498.0  15077.510078 -230.186307 -184.952557 -492.490153\n",
       "997  -97.763893 -498.5  15107.801402 -230.417418 -185.138252 -492.987353\n",
       "998  -97.861951 -499.0  15138.123123 -230.648529 -185.323948 -493.484555\n",
       "999  -97.960010 -499.5  15168.475242 -230.879639 -185.509643 -493.981759\n",
       "1000 -98.058068 -500.0  15198.857759 -231.110750 -185.695338 -494.478964"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Generate data for the random forrest model to train on\n",
    "\n",
    "results = []\n",
    "for v_val in np.linspace(0,1000,1001):\n",
    "    #global v, results\n",
    "    v = v_val\n",
    "    pot_soft = potential_softcore(x, 0)\n",
    "    H = H_without_V + gen_diag_V(x, potential_softcore, 0)\n",
    "    min_eigval = eigsh(H, k=1, sigma=-550)[0][0]\n",
    "    result = describe_potential(pot_soft)\n",
    "    result.append(min_eigval)\n",
    "    results.append(result)\n",
    "\n",
    "df = pd.DataFrame.from_records(results,columns=['max','min','variance','mean','median','min_eigval'])\n",
    "df.to_csv('PotentialsCorrespondingEigenvalues.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>variance</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>min_eigval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-49.029034</td>\n",
       "      <td>-250.000000</td>\n",
       "      <td>5068.819063</td>\n",
       "      <td>-115.555375</td>\n",
       "      <td>-92.847669</td>\n",
       "      <td>-246.342235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28.349383</td>\n",
       "      <td>144.554056</td>\n",
       "      <td>4538.503659</td>\n",
       "      <td>66.815992</td>\n",
       "      <td>53.686028</td>\n",
       "      <td>143.261569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-98.058068</td>\n",
       "      <td>-500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-231.110750</td>\n",
       "      <td>-185.695338</td>\n",
       "      <td>-494.478964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-73.543551</td>\n",
       "      <td>-375.000000</td>\n",
       "      <td>949.928610</td>\n",
       "      <td>-173.333063</td>\n",
       "      <td>-139.271504</td>\n",
       "      <td>-370.227726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-49.029034</td>\n",
       "      <td>-250.000000</td>\n",
       "      <td>3799.714440</td>\n",
       "      <td>-115.555375</td>\n",
       "      <td>-92.847669</td>\n",
       "      <td>-246.115813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-24.514517</td>\n",
       "      <td>-125.000000</td>\n",
       "      <td>8549.357489</td>\n",
       "      <td>-57.777688</td>\n",
       "      <td>-46.423835</td>\n",
       "      <td>-122.272922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>15198.857759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               max          min      variance         mean       median  \\\n",
       "count  1001.000000  1001.000000   1001.000000  1001.000000  1001.000000   \n",
       "mean    -49.029034  -250.000000   5068.819063  -115.555375   -92.847669   \n",
       "std      28.349383   144.554056   4538.503659    66.815992    53.686028   \n",
       "min     -98.058068  -500.000000      0.000000  -231.110750  -185.695338   \n",
       "25%     -73.543551  -375.000000    949.928610  -173.333063  -139.271504   \n",
       "50%     -49.029034  -250.000000   3799.714440  -115.555375   -92.847669   \n",
       "75%     -24.514517  -125.000000   8549.357489   -57.777688   -46.423835   \n",
       "max      -0.000000    -0.000000  15198.857759     0.000000     0.000000   \n",
       "\n",
       "        min_eigval  \n",
       "count  1001.000000  \n",
       "mean   -246.342235  \n",
       "std     143.261569  \n",
       "min    -494.478964  \n",
       "25%    -370.227726  \n",
       "50%    -246.115813  \n",
       "75%    -122.272922  \n",
       "max       0.012292  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df, train_size=0.85)\n",
    "\n",
    "#model = AdaBoostRegressor(loss='square', n_estimators=400, learning_rate=1) \n",
    "model = NN(hidden_layer_sizes=(100,90,100), solver='lbfgs')\n",
    "train_inputs, train_outputs = train[['max','min','variance','mean','median']], train[['min_eigval']]\n",
    "test_inputs, test_outputs = test[['max','min','variance','mean','median']], test[['min_eigval']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1306: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 90, 100), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_inputs, train_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999640342355152"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(test_inputs,test_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-434.2897954]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "879   -434.327993\n",
       "Name: min_eigval, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.predict(test.tail(1)[['max','min','variance','mean','median']]))\n",
    "test.tail(1).min_eigval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['min_eigvalue_NN.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model,'min_eigvalue_NN.joblib') # save the model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_from_describe_potential(desc):\n",
    "    return pd.DataFrame.from_records(desc,columns=['max','min','variance','mean','median'])\n",
    "\n",
    "x_new = np.linspace(-10,10,10000)\n",
    "v = np.random.randint(0,1000)\n",
    "H_test_without_V = gen_diag_Hamiltonian(x_new) \n",
    "H_test = H_test_without_V + gen_diag_V(x_new, potential_softcore, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.2 s ± 6.12 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit eigsh(H_test, k=1, sigma=-10000000) \n",
    "# overestimating the most -ve eigenvalue in the guess, would be unfeasibly long to work out all eigenvals and sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 ms ± 6.32 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit eigsh(H_test, k=1, sigma=model.predict(make_df_from_describe_potential([describe_potential(potential_softcore(x_new,0))]))[0])\n",
    "# Made sure this timing includes the model predicting the eigenvalue, and all extra steps for a fair comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
